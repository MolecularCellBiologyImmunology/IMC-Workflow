Insights for Normalizaiton and clustering 

Why normalization?			
Normalization is required in Imaging Mass Cytometry (IMC) to mitigate technical variability that arises independently of biological differences.	IMC signal intensity is influenced by multiple non-biological factors, including laser ablation efficiency, plasma stability, detector sensitivity, metal isotope–specific transmission, and slide-to-slide or run-to-run staining variability. These sources of variation can lead to systematic differences in signal intensity across regions of interest, slides, or acquisition batches, even when identical tissues or markers are measured. Without normalization,
such technical fluctuations may confound quantitative comparisons of marker expression,obscure true biological patterns, and introduce batch-driven artifacts in downstream single-cell and spatial analyses.Normalization is therefore applied to harmonize signal intensities across comparable samples while preserving genuine biological heterogeneity, enabling robust comparison of marker expression across regions, samples, and experimental conditions.			
			
Normalization Method: 		

To reduce technical variability in Imaging Mass Cytometry (IMC) data, a two-step normalization and scaling procedure was applied, addressing variability both within individual image stacks and across multiple image stacks.

First, normalization was performed independently for each image stack using Xenon132 as a technical reference channel. Xenon132 is a driver gas–derived signal in IMC and is expected to be detected at comparable levels across different acquisitions, independent of tissue type or biological state. For each image stack, a normalization factor was calculated based on the median intensity of the Xenon132 channel, and all marker channels within the same stack were scaled by this factor such that the Xenon132 median intensity was set to 1. This step corrects for stack-specific differences in overall signal intensity caused by variation in laser ablation efficiency, plasma stability, or detector sensitivity.
Second, after concatenation of all normalized image stacks, marker-specific scaling was applied across the combined dataset. Because different antibodies exhibit distinct binding affinities and dynamic intensity ranges, direct comparison of absolute signal intensities between different markers is not meaningful. Therefore, each marker channel was scaled independently using only signal values above a predefined threshold. For each channel, a scaling factor was derived such that a high percentile of the intensity distribution (e.g. the 99th percentile) was set to 1. This scaling step harmonizes the dynamic range of each marker while reducing the influence of extreme values, without altering relative expression differences between cells. 
During marker-specific scaling, a minimum intensity threshold of 0.01 was applied when estimating scaling factors( this depends on the different dataset ). Only values exceeding this threshold were used to compute the high-percentile reference for each marker. This approach excludes background-level and near-zero intensities, which primarily reflect technical noise rather than true marker expression, from influencing the scaling factor. Importantly, the threshold was applied solely for scaling factor estimation; all values, including those below the threshold, were retained in the final scaled dataset. This strategy improves the robustness of percentile-based scaling while preserving the full dynamic range of marker expression.


Throughout the normalization and scaling process, non-marker variables such as spatial coordinates, morphological features, and sample metadata were excluded from intensity transformations and reintroduced afterward. The effectiveness of normalization was evaluated by inspecting marker intensity distributions before and after processing to ensure that technical variation was reduced without distorting biologically meaningful signal patterns.
